{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       7.051798\n",
      "1       5.109559\n",
      "2       8.067315\n",
      "3      14.479588\n",
      "4      10.306761\n",
      "5      15.840082\n",
      "6      12.434699\n",
      "7       6.232905\n",
      "8      19.087452\n",
      "9      15.162804\n",
      "10      7.868631\n",
      "11     11.596669\n",
      "12     14.518980\n",
      "13     10.426753\n",
      "14     15.937560\n",
      "15     14.904775\n",
      "16     13.906409\n",
      "17     10.422671\n",
      "18      3.936722\n",
      "19     10.656168\n",
      "20     14.374287\n",
      "21     16.627227\n",
      "22     15.363897\n",
      "23     12.985381\n",
      "24      8.006484\n",
      "25      8.261243\n",
      "26     12.146115\n",
      "27     17.357421\n",
      "28     11.764741\n",
      "29     12.271838\n",
      "         ...    \n",
      "813    14.414188\n",
      "814    12.692388\n",
      "815    19.116584\n",
      "816    11.331456\n",
      "817    13.321100\n",
      "818    12.238471\n",
      "819    12.726367\n",
      "820    10.169563\n",
      "821    11.310766\n",
      "822    17.850394\n",
      "823     7.497267\n",
      "824    11.834318\n",
      "825    10.893387\n",
      "826     9.716379\n",
      "827     6.799232\n",
      "828    14.959848\n",
      "829     9.043786\n",
      "830    10.931777\n",
      "831     7.937533\n",
      "832    11.988759\n",
      "833    12.845945\n",
      "834    16.705689\n",
      "835    -0.244143\n",
      "836     9.475493\n",
      "837    13.856640\n",
      "839    11.702135\n",
      "840    11.225237\n",
      "841    11.983039\n",
      "842    11.668825\n",
      "843    17.543959\n",
      "Name: G3, Length: 505, dtype: float64\n",
      "Lin Variance score: 0.84\n",
      "Lin Mean squared error regression loss: 2.81\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.2.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "# os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "# import xgboost\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "%matplotlib inline\n",
    "\n",
    "# df_math = pd.read_csv('student-mat.csv')\n",
    "# df_por = pd.read_csv('student-por.csv')\n",
    "\n",
    "# df = [df_math, df_por]\n",
    "# df = pd.concat(df)\n",
    "\n",
    "df = pd.read_csv('student-train.csv')\n",
    "\n",
    "df=df.drop_duplicates([\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"])\n",
    "\n",
    "#Sum all the alc\n",
    "df['Dalc'] = df['Dalc'] + df['Walc']\n",
    "\n",
    "df.replace(['yes','no'],[1,0], inplace = True)\n",
    "df['school'] = df.loc[:,'school'].replace(['GP','MS'], [1,0])\n",
    "df['sex'] = df.loc[:,'sex'].replace(['M','F'], [1,0])\n",
    "df['address'] = df.loc[:,'address'].replace(['U','R'], [1,0])\n",
    "df['famsize'] = df.loc[:,'famsize'].replace(['LE3','GT3'], [1,0])\n",
    "df['Pstatus'] = df.loc[:,'Pstatus'].replace(['T','A'], [1,0])\n",
    "\n",
    "df_with_dumnies = pd.get_dummies(df,columns=['Mjob', 'Fjob', 'reason', 'guardian'])\n",
    "\n",
    "df_with_dumnies_2 = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin(['G1', 'G2', 'G3'])]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "linreg1 = LinearRegression()\n",
    "linreg2 = LinearRegression()\n",
    "linreg3 = LinearRegression()\n",
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE)\n",
    "\n",
    "df_with_dumnies_lin = df_with_dumnies_2.copy()\n",
    "\n",
    "# Dummie G1 prediction\n",
    "TARGET = 'G1'\n",
    "\n",
    "df_with_dumnies_lin['G1'] = 0\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET])]\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    linreg1.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    G_pred_lin = linreg1.predict(X.iloc[test_idx])\n",
    "    df_with_dumnies_lin['G1'].iloc[test_idx] = G_pred_lin\n",
    "\n",
    "# Dummie G2 prediction\n",
    "TARGET = 'G2'\n",
    "\n",
    "df_with_dumnies_lin['G2'] = 0\n",
    "\n",
    "y2 = df_with_dumnies.loc[:,TARGET]\n",
    "X2 = df_with_dumnies_lin.loc[:,~df_with_dumnies_lin.columns.isin([TARGET])]\n",
    "\n",
    "for train_idx, test_idx in skf.split(X2, y2):\n",
    "    linreg2.fit(X2.iloc[train_idx], y2.iloc[train_idx])\n",
    "    G_pred_lin = linreg2.predict(X2.iloc[test_idx])\n",
    "    df_with_dumnies_lin['G2'].iloc[test_idx] = G_pred_lin\n",
    "\n",
    "# Dummie G3 prediction\n",
    "TARGET = 'G3'\n",
    "\n",
    "y3 = df_with_dumnies.loc[:,TARGET]\n",
    "X3 = df_with_dumnies_lin\n",
    "\n",
    "y_pred = y3.copy()\n",
    "\n",
    "for train_idx, test_idx in skf.split(X3, y3):\n",
    "    linreg3.fit(X3.iloc[train_idx], y3.iloc[train_idx])\n",
    "    G_pred_lin = linreg3.predict(X3.iloc[test_idx])\n",
    "    y_pred.iloc[test_idx] = G_pred_lin\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y3, y_pred))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y3, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(df.corr(),annot = True, fmt = \".2f\", cbar = True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'G1'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET, 'G2', 'G3'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=RANDOM_STATE)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "y_pred_lin = linreg.predict(X_test)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y_pred,y_test))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score xgb:\n",
    "print('XGB Variance score: %.2f' % explained_variance_score(y_pred_xgb,y_test))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('XGB Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Feature %s (%f)\" % (f + 1, X.columns.values[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'G2'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET, 'G1', 'G3'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=RANDOM_STATE)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y_pred,y_test))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score xgb:\n",
    "print('XGB Variance score: %.2f' % explained_variance_score(y_pred_xgb,y_test))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('XGB Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Feature %s (%f)\" % (f + 1, X.columns.values[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'G2'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET, 'G3'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=RANDOM_STATE)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y_pred,y_test))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score xgb:\n",
    "print('XGB Variance score: %.2f' % explained_variance_score(y_pred_xgb,y_test))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('XGB Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Feature %s (%f)\" % (f + 1, X.columns.values[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'G3'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET, 'G1', 'G2'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=RANDOM_STATE)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y_pred,y_test))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score xgb:\n",
    "print('XGB Variance score: %.2f' % explained_variance_score(y_pred_xgb,y_test))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('XGB Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Feature %s (%f)\" % (f + 1, X.columns.values[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'G3'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET, 'G2'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=RANDOM_STATE)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y_pred,y_test))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score xgb:\n",
    "print('XGB Variance score: %.2f' % explained_variance_score(y_pred_xgb,y_test))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('XGB Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Feature %s (%f)\" % (f + 1, X.columns.values[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'G3'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET, 'G1'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=RANDOM_STATE)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y_pred,y_test))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score xgb:\n",
    "print('XGB Variance score: %.2f' % explained_variance_score(y_pred_xgb,y_test))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('XGB Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Feature %s (%f)\" % (f + 1, X.columns.values[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'G3'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,random_state=RANDOM_STATE)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y_pred,y_test))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score xgb:\n",
    "print('XGB Variance score: %.2f' % explained_variance_score(y_pred_xgb,y_test))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('XGB Mean squared error regression loss: %.2f' % mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. Feature %s (%f)\" % (f + 1, X.columns.values[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_dumnies_2 = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin(['G1', 'G2', 'G3'])]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "linreg = LinearRegression()\n",
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE)\n",
    "\n",
    "# Dummie G1 prediction\n",
    "TARGET = 'G1'\n",
    "\n",
    "df_with_dumnies_lin = df_with_dumnies_2.copy()\n",
    "\n",
    "df_with_dumnies_lin['G1'] = None\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET])]\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    linreg.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    G_pred_lin = linreg.predict(X.iloc[test_idx])\n",
    "    df_with_dumnies_lin['G1'].iloc[test_idx] = G_pred_lin\n",
    "\n",
    "# Dummie G2 prediction\n",
    "TARGET = 'G2'\n",
    "\n",
    "df_with_dumnies_lin['G2'] = None\n",
    "\n",
    "y2 = df_with_dumnies.loc[:,TARGET]\n",
    "X2 = df_with_dumnies_lin.loc[:,~df_with_dumnies_lin.columns.isin([TARGET])]\n",
    "\n",
    "for train_idx, test_idx in skf.split(X2, y2):\n",
    "    linreg.fit(X2.iloc[train_idx], y2.iloc[train_idx])\n",
    "    G_pred_lin = linreg.predict(X2.iloc[test_idx])\n",
    "    df_with_dumnies_lin['G2'].iloc[test_idx] = G_pred_lin\n",
    "\n",
    "# Dummie G3 prediction\n",
    "TARGET = 'G3'\n",
    "\n",
    "y3 = df_with_dumnies.loc[:,TARGET]\n",
    "X3 = df_with_dumnies_lin\n",
    "\n",
    "y_pred = y3.copy()\n",
    "\n",
    "for train_idx, test_idx in skf.split(X3, y3):\n",
    "    linreg.fit(X3.iloc[train_idx], y3.iloc[train_idx])\n",
    "    G_pred_lin = linreg.predict(X3.iloc[test_idx])\n",
    "    y_pred.iloc[test_idx] = G_pred_lin\n",
    "    \n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y3, y_pred))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y3, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_dumnies_2 = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin(['G1', 'G2', 'G3'])]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE)\n",
    "\n",
    "# Dummie G1 prediction\n",
    "TARGET = 'G1'\n",
    "\n",
    "df_with_dumnies_xgb = df_with_dumnies_2.copy()\n",
    "\n",
    "df_with_dumnies_xgb['G1'] = None\n",
    "\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET])]\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    xgb.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    G_pred_xgb = xgb.predict(X.iloc[test_idx])\n",
    "    df_with_dumnies_xgb['G1'].iloc[test_idx] = G_pred_xgb\n",
    "\n",
    "# Dummie G2 prediction\n",
    "TARGET = 'G2'\n",
    "\n",
    "df_with_dumnies_xgb['G2'] = 0\n",
    "\n",
    "y2 = df_with_dumnies.loc[:,TARGET]\n",
    "X2 = df_with_dumnies_xgb.loc[:,~df_with_dumnies_xgb.columns.isin([TARGET])]\n",
    "X2['G1'] = X2['G1'].astype('float')\n",
    "\n",
    "for train_idx, test_idx in skf.split(X2, y2):\n",
    "    xgb.fit(X2.loc[train_idx], y2.loc[train_idx])\n",
    "    G_pred_xgb = xgb.predict(X2.iloc[test_idx])\n",
    "    df_with_dumnies_xgb['G2'].iloc[test_idx] = G_pred_xgb\n",
    "\n",
    "# Dummie G3 prediction\n",
    "TARGET = 'G3'\n",
    "\n",
    "y3 = df_with_dumnies.loc[:,TARGET]\n",
    "X3 = df_with_dumnies_xgb\n",
    "X3['G1'] = X3['G1'].astype('float')\n",
    "\n",
    "y_pred = y3.copy()\n",
    "\n",
    "for train_idx, test_idx in skf.split(X3, y3):\n",
    "    xgb.fit(X3.iloc[train_idx], y2.iloc[train_idx])\n",
    "    G_pred_xgb = xgb.predict(X3.iloc[test_idx])\n",
    "    y_pred.iloc[test_idx] = G_pred_xgb\n",
    "    \n",
    "# Explained variance score xgb:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y3, y_pred))\n",
    "# Mean squared error regression loss xgb:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y3, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\212632683\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      14.220149\n",
      "1      16.343252\n",
      "2      11.330665\n",
      "3      11.229265\n",
      "4       6.880968\n",
      "6       9.859097\n",
      "7      14.508877\n",
      "8      11.608617\n",
      "9      11.622146\n",
      "10      9.823545\n",
      "11     10.099682\n",
      "12     12.990087\n",
      "13     16.185194\n",
      "14     11.217117\n",
      "15     11.058829\n",
      "16      7.618541\n",
      "17      9.976224\n",
      "18     14.066892\n",
      "19     13.632028\n",
      "20     12.426492\n",
      "21     13.030116\n",
      "22     11.661867\n",
      "23     15.551278\n",
      "24      7.932919\n",
      "25     12.144501\n",
      "26     13.916237\n",
      "27      9.029032\n",
      "28     10.944196\n",
      "29      5.825588\n",
      "30     10.732431\n",
      "         ...    \n",
      "169    16.804350\n",
      "170    13.683766\n",
      "171    14.421305\n",
      "172    13.499436\n",
      "173     9.964385\n",
      "174    16.828077\n",
      "175    10.314654\n",
      "176    10.600186\n",
      "177     4.340510\n",
      "178    10.969180\n",
      "179    11.930611\n",
      "180     8.374597\n",
      "181    18.432451\n",
      "182    12.935503\n",
      "183     8.714391\n",
      "184    14.884068\n",
      "185    16.833800\n",
      "186     9.913651\n",
      "187    18.978053\n",
      "188     7.071919\n",
      "189    15.088986\n",
      "190     7.464459\n",
      "191     5.371568\n",
      "192    18.242941\n",
      "193    10.084953\n",
      "194    11.958857\n",
      "195    11.584909\n",
      "196    15.840329\n",
      "198    10.071291\n",
      "199    12.920701\n",
      "Name: G3, Length: 197, dtype: float64\n",
      "Lin Variance score: 0.85\n",
      "Lin Mean squared error regression loss: 2.64\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE)\n",
    "df = pd.read_csv('student-test.csv')\n",
    "df=df.drop_duplicates([\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"])  \n",
    "\n",
    "#Preparing dataframe\n",
    "df['Dalc'] = df['Dalc'] + df['Walc']\n",
    "df.replace(['yes','no'],[1,0], inplace = True)\n",
    "df['school'] = df.loc[:,'school'].replace(['GP','MS'], [1,0])\n",
    "df['sex'] = df.loc[:,'sex'].replace(['M','F'], [1,0])\n",
    "df['address'] = df.loc[:,'address'].replace(['U','R'], [1,0])\n",
    "df['famsize'] = df.loc[:,'famsize'].replace(['LE3','GT3'], [1,0])\n",
    "df['Pstatus'] = df.loc[:,'Pstatus'].replace(['T','A'], [1,0])\n",
    "df_with_dumnies = pd.get_dummies(df,columns=['Mjob', 'Fjob', 'reason', 'guardian']) \n",
    "\n",
    "df_with_dumnies_lin = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin(['G1', 'G2', 'G3'])]\n",
    "\n",
    "TARGET = 'G1'\n",
    "df_with_dumnies_lin['G1'] = None\n",
    "y = df_with_dumnies.loc[:,TARGET]\n",
    "X = df_with_dumnies.loc[:,~df_with_dumnies.columns.isin([TARGET])]\n",
    "\n",
    "#Predic G1\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    G_pred_lin = linreg1.predict(X.iloc[test_idx])\n",
    "    df_with_dumnies_lin['G1'].iloc[test_idx] = G_pred_lin\n",
    "\n",
    "#Predic G2\n",
    "TARGET = 'G2'\n",
    "\n",
    "df_with_dumnies_lin['G2'] = 0\n",
    "\n",
    "y2 = df_with_dumnies.loc[:,TARGET]\n",
    "X2 = df_with_dumnies_lin.loc[:,~df_with_dumnies_lin.columns.isin([TARGET])]\n",
    "\n",
    "for train_idx, test_idx in skf.split(X2, y2):\n",
    "    G_pred_lin = linreg2.predict(X2.iloc[test_idx])\n",
    "    df_with_dumnies_lin['G2'].iloc[test_idx] = G_pred_lin\n",
    "            \n",
    "#Predic G3\n",
    "TARGET = 'G3'\n",
    "\n",
    "y3 = df_with_dumnies.loc[:,TARGET]\n",
    "X3 = df_with_dumnies_lin\n",
    "\n",
    "y_pred = y3.copy()\n",
    "\n",
    "for train_idx, test_idx in skf.split(X3, y3):\n",
    "    G_pred_lin = linreg3.predict(X3.iloc[test_idx])\n",
    "    y_pred.iloc[test_idx] = G_pred_lin\n",
    "\n",
    "print(y_pred)\n",
    "# Explained variance score lin:\n",
    "print('Lin Variance score: %.2f' % explained_variance_score(y3, y_pred))\n",
    "# Mean squared error regression loss lin:\n",
    "print('Lin Mean squared error regression loss: %.2f' % mean_squared_error(y3, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
